<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Victor's Blog (shadertoy)</title><link>https://victor-shepardson.github.io/blog/</link><description></description><atom:link type="application/rss+xml" rel="self" href="https://victor-shepardson.github.io/blog/categories/shadertoy.xml"></atom:link><language>en</language><lastBuildDate>Mon, 16 Jan 2017 22:54:37 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Video Feedback</title><link>https://victor-shepardson.github.io/blog/posts/video-feedback/</link><dc:creator>Victor Shepardson</dc:creator><description>&lt;div&gt;&lt;p&gt;Way back in high school I read Douglas Hofstadter's &lt;a href="https://archive.org/details/GEBen_201404"&gt;Gödel, Escher, Bach&lt;/a&gt;. If you aren't familiar, I have to advise you to go read it instead of looking at my dumb blog. There are about a hundred captivating ideas in there, and just one of them is the concept of video feedback: connect a video camera to a screen, and then point it at the screen. Weird stuff happens on the screen. (Meanwhile I was learning to play the guitar, and discovering that the electro-acoustic feedback of wiggling the thing around in front of an amp is much more fun than drilling scales.)&lt;/p&gt;
&lt;iframe src="https://archive.org/stream/GEBen_201404/GEBen?ui=embed#page/n496/mode/1up" width="480px" height="430px" frameborder="0"&gt;&lt;/iframe&gt;

&lt;p&gt;As an undergrad, I became interested in computer graphics. (I know of two things that teach you to really see: studying the science of computer graphics, and learning to paint or draw from life.) I was especially taken with the idea of &lt;em&gt;procedural graphics&lt;/em&gt;: generating images from nothing but math, as opposed to using assets made by virtually drawing (as in photoshop) or digitizing reality (as with a digital camera). Procedural graphics can translate some of the tantalizing infinites of mathematics into rich sensory experiences! In particular &lt;a href="http://www.iquilezles.org/www/articles/warp/warp.htm"&gt;this brief article&lt;/a&gt; by Íñigo Quílez had me enthralled by the idea of turning a random number generator into an endless alien terrain.&lt;/p&gt;
&lt;p&gt;Eventually I put two and two together: you can dispense with the video camera and program a completely virtual video feedback process. And once you do, it can do much weirder things than a video camera. This was hardly unknown in computer graphics, yet was weirdly unpopular. There's a preoccupation with statelessness in the scene Quílez is part of; &lt;a href="https://www.shadertoy.com/"&gt;Shadertoy&lt;/a&gt; didn't render to texture until 2016! Academic CG tends to focus on predictability and utility for efficient, photorealistic rendering; feedback is unruly and difficult to analyze. Then there are fractals, which are iterated, but not open ended: you iterate to convergence, rather than letting the image evolve as in video feedback. However &lt;a href="http://csc.ucdavis.edu/~chaos/"&gt;Jim Crutchfield&lt;/a&gt; has written about the dynamics of digital video feedback from a math/physics perspective. 2-D cellular automata like Conway's game of life can be thought of as digital video feedback, and there's a whole &lt;a href="http://golly.sourceforge.net/"&gt;hobbyist community&lt;/a&gt; there, not to mention the &lt;a href="http://alife.org/"&gt;academic artificial life community&lt;/a&gt; or &lt;a href="http://www.wolframscience.com/"&gt;Stephen Wolfram&lt;/a&gt;'s insular "new kind of science". The whole field of computational fluid dynamics is doing a similar thing with a different set of priorities! And of course video feedback shows up in fine art beginning (?) with video artists like Nam June Paik.&lt;/p&gt;
&lt;p&gt;Finally in the fall of 2014 after encountering such cool dudes as &lt;a href="http://sabrinaratte.com/"&gt;Sabrina Ratté&lt;/a&gt; and &lt;a href="http://www.alexanderdupuis.com/"&gt;Alex Dupuis&lt;/a&gt; I was galvanized to get some feedback of my own going. Still blissfully ignorant of much, I started making stuff like this (more recent) doodle:&lt;/p&gt;
&lt;iframe width="100%" height="332" frameborder="0" src="https://www.shadertoy.com/embed/MdcSW8?gui=true&amp;amp;t=10&amp;amp;paused=false&amp;amp;muted=false" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;(Incidentally &lt;a href="https://synesthesia.live/"&gt;these folks&lt;/a&gt; licensed the above shader to use in their music-reactive visuals software Synesthesia. It looks pretty neat, though I haven't been able to mess with it myself since I don't have a Mac. Maybe take a look if you do.)&lt;/p&gt;
&lt;p&gt;Eventually this would grow into such projects as &lt;a href="https://victor-shepardson.github.io/blog/posts/abstract-concrete/"&gt;ABSTRACT/CONCRETE&lt;/a&gt;, &lt;a href="https://victor-shepardson.github.io/blog/posts/convnet-video-feedback/"&gt;Video Synthesis With Convolutional Autoencoders&lt;/a&gt; and &lt;a href="https://victor-shepardson.github.io/blog/posts/cortical-sonification"&gt;Data Sonification Using a Cortical Representation of Sound&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>douglas hofstadter</category><category>feedback</category><category>shadertoy</category><category>visual</category><guid>https://victor-shepardson.github.io/blog/posts/video-feedback/</guid><pubDate>Thu, 12 Jan 2017 03:08:22 GMT</pubDate></item></channel></rss>