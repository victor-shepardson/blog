<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>~/blog (Posts about video)</title><link>https://victor-shepardson.github.io/blog/</link><description></description><atom:link href="https://victor-shepardson.github.io/blog/categories/video.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 24 Apr 2018 03:15:45 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Video Feedback</title><link>https://victor-shepardson.github.io/blog/posts/video-feedback/</link><dc:creator>Victor Shepardson</dc:creator><description>&lt;div&gt;&lt;p&gt;Douglas Hofstadter's &lt;a href="https://archive.org/details/GEBen_201404"&gt;Gödel, Escher, Bach&lt;/a&gt; contains about a hundred captivating ideas, and just one of them is the concept of video feedback: connect a video camera to a screen, and then point it at the screen. Weird stuff happens on the screen as light is projected though the air, captured by the camera and circled back to the screen, mutating each time. Zoom out to get a infinite hall of mirrors effect, zoom in to get kaleidoscopic pulsations, loosen the focus to get bubbling slime.&lt;/p&gt;
&lt;p&gt;As an undergrad, I became interested in computer graphics. Particularly, the idea of &lt;em&gt;procedural graphics&lt;/em&gt;: generating images from nothing but math, as opposed to using assets made by virtually drawing (as with photoshop) or digitizing reality (as with a digital camera). Procedural graphics can translate some of the tantalizing infinites of mathematics into rich sensory experiences! &lt;a href="http://www.iquilezles.org/www/articles/warp/warp.htm"&gt;This brief article&lt;/a&gt; by Íñigo Quílez introduced me to the idea of turning a random number generator into an endless alien terrain. One popular way to do this is with &lt;em&gt;fragment shaders&lt;/em&gt;, specialized programs for doing pixel-by-pixel graphics with the GPUs found in most computers. For more than a few examples, see &lt;a href="https://www.shadertoy.com/"&gt;Shadertoy&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;You can put a fragment shader into feedback just like a video camera. Pixels go in, pixels come out, pixels go back in 60 times per second. The shader determines how colors mutate and interact with nearby colors each time. Here are a few of mine:&lt;/p&gt;
&lt;iframe width="100%" height="256" frameborder="0" src="https://www.shadertoy.com/embed/4d2BRm?gui=true&amp;amp;t=10&amp;amp;paused=true&amp;amp;muted=false" allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width="100%" height="256" frameborder="0" src="https://www.shadertoy.com/embed/lt2yz3?gui=true&amp;amp;t=10&amp;amp;paused=true&amp;amp;muted=false" allowfullscreen&gt;&lt;/iframe&gt;

&lt;iframe width="100%" height="256" frameborder="0" src="https://www.shadertoy.com/embed/lsBcRK?gui=true&amp;amp;t=10&amp;amp;paused=true&amp;amp;muted=false" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;A few other people working with this kind of stuff:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://sabrinaratte.com/"&gt;Sabrina Ratté&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://alexanderdupuis.com/"&gt;Alex Dupuis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pixlpa.com/"&gt;Andrew Benson&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://twitter.com/Flexi23"&gt;Felix Woitzel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A few other things which resemble digital video feedback:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2D Cellular automata like &lt;a href="http://golly.sourceforge.net/"&gt;Conway's game of life&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Finite element physical simulations of fluids and &lt;a href="https://pmneila.github.io/jsexp/grayscott/"&gt;reaction-diffusion systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I just can't stay away. See projects such as &lt;a href="https://victor-shepardson.github.io/blog/posts/abstract-concrete/"&gt;ABSTRACT/CONCRETE&lt;/a&gt;, &lt;a href="https://victor-shepardson.github.io/blog/posts/convnet-video-feedback/"&gt;Video Synthesis With Convolutional Autoencoders&lt;/a&gt; and &lt;a href="https://victor-shepardson.github.io/blog/posts/cortical-sonification"&gt;Data Sonification Using a Cortical Representation of Sound&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>feedback</category><category>generative</category><category>shader</category><category>video</category><category>visual</category><guid>https://victor-shepardson.github.io/blog/posts/video-feedback/</guid><pubDate>Thu, 12 Jan 2017 03:08:22 GMT</pubDate></item></channel></rss>